[*] Run ID 0: seed=0, split_index=0
    Starting now: 2024-02-27 09:51:52.456766
[*] Loaded dataset 'subset' from 'PyG-ZINC':
  Data(x=[277864, 1], edge_index=[2, 597970], edge_attr=[597970], y=[12000])
  undirected: True
  num graphs: 12000
  avg num_nodes/graph: 23
  num node features: 1
  num edge features: 1
  num classes: (appears to be a regression task)
Precomputing Positional Encoding statistics: ['PPR'] for all graphs...
  ...estimated to be undirected: True
Done! Took 00:11:13.01
GraphGymModule(
  (model): GritTransformer(
    (encoder): FeatureEncoder(
      (node_encoder): Concat2NodeEncoder(
        (encoder1): TypeDictNodeEncoder(
          (encoder): Embedding(21, 60)
        )
        (encoder2): PPRNodeEncoder()
      )
      (edge_encoder): TypeDictEdgeEncoder(
        (encoder): Embedding(4, 64)
      )
    )
    (layers): Sequential(
      (0): GritTransformerLayer(in_channels=64, out_channels=64, heads=8, residual=True)
      [GritTransformerLayer(
        (act): ReLU()
        (attention): MultiHeadAttentionLayerGritSparse(
          (dropout): Dropout(p=0.2, inplace=False)
          (Q): Linear(in_features=64, out_features=64, bias=True)
          (K): Linear(in_features=64, out_features=64, bias=False)
          (E): Linear(in_features=64, out_features=128, bias=True)
          (V): Linear(in_features=64, out_features=64, bias=False)
          (act): ReLU()
        )
        (O_h): Linear(in_features=64, out_features=64, bias=True)
        (O_e): Linear(in_features=64, out_features=64, bias=True)
        (batch_norm1_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (batch_norm1_e): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (FFN_h_layer1): Linear(in_features=64, out_features=128, bias=True)
        (FFN_h_layer2): Linear(in_features=128, out_features=64, bias=True)
        (batch_norm2_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )]
      (1): GritTransformerLayer(in_channels=64, out_channels=64, heads=8, residual=True)
      [GritTransformerLayer(
        (act): ReLU()
        (attention): MultiHeadAttentionLayerGritSparse(
          (dropout): Dropout(p=0.2, inplace=False)
          (Q): Linear(in_features=64, out_features=64, bias=True)
          (K): Linear(in_features=64, out_features=64, bias=False)
          (E): Linear(in_features=64, out_features=128, bias=True)
          (V): Linear(in_features=64, out_features=64, bias=False)
          (act): ReLU()
        )
        (O_h): Linear(in_features=64, out_features=64, bias=True)
        (O_e): Linear(in_features=64, out_features=64, bias=True)
        (batch_norm1_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (batch_norm1_e): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (FFN_h_layer1): Linear(in_features=64, out_features=128, bias=True)
        (FFN_h_layer2): Linear(in_features=128, out_features=64, bias=True)
        (batch_norm2_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )]
      (2): GritTransformerLayer(in_channels=64, out_channels=64, heads=8, residual=True)
      [GritTransformerLayer(
        (act): ReLU()
        (attention): MultiHeadAttentionLayerGritSparse(
          (dropout): Dropout(p=0.2, inplace=False)
          (Q): Linear(in_features=64, out_features=64, bias=True)
          (K): Linear(in_features=64, out_features=64, bias=False)
          (E): Linear(in_features=64, out_features=128, bias=True)
          (V): Linear(in_features=64, out_features=64, bias=False)
          (act): ReLU()
        )
        (O_h): Linear(in_features=64, out_features=64, bias=True)
        (O_e): Linear(in_features=64, out_features=64, bias=True)
        (batch_norm1_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (batch_norm1_e): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (FFN_h_layer1): Linear(in_features=64, out_features=128, bias=True)
        (FFN_h_layer2): Linear(in_features=128, out_features=64, bias=True)
        (batch_norm2_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )]
      (3): GritTransformerLayer(in_channels=64, out_channels=64, heads=8, residual=True)
      [GritTransformerLayer(
        (act): ReLU()
        (attention): MultiHeadAttentionLayerGritSparse(
          (dropout): Dropout(p=0.2, inplace=False)
          (Q): Linear(in_features=64, out_features=64, bias=True)
          (K): Linear(in_features=64, out_features=64, bias=False)
          (E): Linear(in_features=64, out_features=128, bias=True)
          (V): Linear(in_features=64, out_features=64, bias=False)
          (act): ReLU()
        )
        (O_h): Linear(in_features=64, out_features=64, bias=True)
        (O_e): Linear(in_features=64, out_features=64, bias=True)
        (batch_norm1_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (batch_norm1_e): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (FFN_h_layer1): Linear(in_features=64, out_features=128, bias=True)
        (FFN_h_layer2): Linear(in_features=128, out_features=64, bias=True)
        (batch_norm2_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )]
      (4): GritTransformerLayer(in_channels=64, out_channels=64, heads=8, residual=True)
      [GritTransformerLayer(
        (act): ReLU()
        (attention): MultiHeadAttentionLayerGritSparse(
          (dropout): Dropout(p=0.2, inplace=False)
          (Q): Linear(in_features=64, out_features=64, bias=True)
          (K): Linear(in_features=64, out_features=64, bias=False)
          (E): Linear(in_features=64, out_features=128, bias=True)
          (V): Linear(in_features=64, out_features=64, bias=False)
          (act): ReLU()
        )
        (O_h): Linear(in_features=64, out_features=64, bias=True)
        (O_e): Linear(in_features=64, out_features=64, bias=True)
        (batch_norm1_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (batch_norm1_e): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (FFN_h_layer1): Linear(in_features=64, out_features=128, bias=True)
        (FFN_h_layer2): Linear(in_features=128, out_features=64, bias=True)
        (batch_norm2_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )]
      (5): GritTransformerLayer(in_channels=64, out_channels=64, heads=8, residual=True)
      [GritTransformerLayer(
        (act): ReLU()
        (attention): MultiHeadAttentionLayerGritSparse(
          (dropout): Dropout(p=0.2, inplace=False)
          (Q): Linear(in_features=64, out_features=64, bias=True)
          (K): Linear(in_features=64, out_features=64, bias=False)
          (E): Linear(in_features=64, out_features=128, bias=True)
          (V): Linear(in_features=64, out_features=64, bias=False)
          (act): ReLU()
        )
        (O_h): Linear(in_features=64, out_features=64, bias=True)
        (O_e): Linear(in_features=64, out_features=64, bias=True)
        (batch_norm1_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (batch_norm1_e): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (FFN_h_layer1): Linear(in_features=64, out_features=128, bias=True)
        (FFN_h_layer2): Linear(in_features=128, out_features=64, bias=True)
        (batch_norm2_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )]
      (6): GritTransformerLayer(in_channels=64, out_channels=64, heads=8, residual=True)
      [GritTransformerLayer(
        (act): ReLU()
        (attention): MultiHeadAttentionLayerGritSparse(
          (dropout): Dropout(p=0.2, inplace=False)
          (Q): Linear(in_features=64, out_features=64, bias=True)
          (K): Linear(in_features=64, out_features=64, bias=False)
          (E): Linear(in_features=64, out_features=128, bias=True)
          (V): Linear(in_features=64, out_features=64, bias=False)
          (act): ReLU()
        )
        (O_h): Linear(in_features=64, out_features=64, bias=True)
        (O_e): Linear(in_features=64, out_features=64, bias=True)
        (batch_norm1_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (batch_norm1_e): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (FFN_h_layer1): Linear(in_features=64, out_features=128, bias=True)
        (FFN_h_layer2): Linear(in_features=128, out_features=64, bias=True)
        (batch_norm2_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )]
      (7): GritTransformerLayer(in_channels=64, out_channels=64, heads=8, residual=True)
      [GritTransformerLayer(
        (act): ReLU()
        (attention): MultiHeadAttentionLayerGritSparse(
          (dropout): Dropout(p=0.2, inplace=False)
          (Q): Linear(in_features=64, out_features=64, bias=True)
          (K): Linear(in_features=64, out_features=64, bias=False)
          (E): Linear(in_features=64, out_features=128, bias=True)
          (V): Linear(in_features=64, out_features=64, bias=False)
          (act): ReLU()
        )
        (O_h): Linear(in_features=64, out_features=64, bias=True)
        (O_e): Linear(in_features=64, out_features=64, bias=True)
        (batch_norm1_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (batch_norm1_e): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (FFN_h_layer1): Linear(in_features=64, out_features=128, bias=True)
        (FFN_h_layer2): Linear(in_features=128, out_features=64, bias=True)
        (batch_norm2_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )]
      (8): GritTransformerLayer(in_channels=64, out_channels=64, heads=8, residual=True)
      [GritTransformerLayer(
        (act): ReLU()
        (attention): MultiHeadAttentionLayerGritSparse(
          (dropout): Dropout(p=0.2, inplace=False)
          (Q): Linear(in_features=64, out_features=64, bias=True)
          (K): Linear(in_features=64, out_features=64, bias=False)
          (E): Linear(in_features=64, out_features=128, bias=True)
          (V): Linear(in_features=64, out_features=64, bias=False)
          (act): ReLU()
        )
        (O_h): Linear(in_features=64, out_features=64, bias=True)
        (O_e): Linear(in_features=64, out_features=64, bias=True)
        (batch_norm1_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (batch_norm1_e): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (FFN_h_layer1): Linear(in_features=64, out_features=128, bias=True)
        (FFN_h_layer2): Linear(in_features=128, out_features=64, bias=True)
        (batch_norm2_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )]
      (9): GritTransformerLayer(in_channels=64, out_channels=64, heads=8, residual=True)
      [GritTransformerLayer(
        (act): ReLU()
        (attention): MultiHeadAttentionLayerGritSparse(
          (dropout): Dropout(p=0.2, inplace=False)
          (Q): Linear(in_features=64, out_features=64, bias=True)
          (K): Linear(in_features=64, out_features=64, bias=False)
          (E): Linear(in_features=64, out_features=128, bias=True)
          (V): Linear(in_features=64, out_features=64, bias=False)
          (act): ReLU()
        )
        (O_h): Linear(in_features=64, out_features=64, bias=True)
        (O_e): Linear(in_features=64, out_features=64, bias=True)
        (batch_norm1_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (batch_norm1_e): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (FFN_h_layer1): Linear(in_features=64, out_features=128, bias=True)
        (FFN_h_layer2): Linear(in_features=128, out_features=64, bias=True)
        (batch_norm2_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )]
    )
    (post_mp): SANGraphHead(
      (FC_layers): ModuleList(
        (0): Linear(in_features=64, out_features=32, bias=True)
        (1): Linear(in_features=32, out_features=16, bias=True)
        (2): Linear(in_features=16, out_features=1, bias=True)
      )
      (activation): ReLU()
    )
  )
)
accelerator: cuda:0
benchmark: False
best_by_loss: False
bn:
  eps: 1e-05
  mom: 0.1
cfg_dest: config.yaml
cfg_file: configs/GRIT/zinc-GRIT-PPR.yaml
custom_metrics: []
dataset:
  cache_load: False
  cache_save: False
  dir: ./datasets
  edge_dim: 128
  edge_encoder: True
  edge_encoder_bn: False
  edge_encoder_name: TypeDictEdge
  edge_encoder_num_types: 4
  edge_message_ratio: 0.8
  edge_negative_sampling_ratio: 1.0
  edge_train_mode: all
  encoder: True
  encoder_bn: True
  encoder_dim: 128
  encoder_name: db
  format: PyG-ZINC
  label_column: none
  label_table: none
  location: local
  name: subset
  node_encoder: True
  node_encoder_bn: False
  node_encoder_name: TypeDictNode+PPR
  node_encoder_num_types: 21
  pe_transform_on_the_fly: False
  remove_feature: False
  resample_disjoint: False
  resample_negative: False
  shuffle_split: True
  slic_compactness: 10
  split: [0.8, 0.1, 0.1]
  split_dir: ./splits
  split_index: 0
  split_mode: standard
  task: graph
  task_type: regression
  to_undirected: False
  transductive: False
  transform: none
  tu_simple: True
device: cuda:0
devices: None
example_arg: example
example_group:
  example_arg: example
gnn:
  act: relu
  agg: mean
  att_final_linear: False
  att_final_linear_bn: False
  att_heads: 1
  batchnorm: True
  clear_feature: True
  dim_edge: 64
  dim_inner: 64
  dropout: 0.0
  head: san_graph
  keep_edge: 0.5
  l2norm: True
  layer_type: generalconv
  layers_mp: 2
  layers_post_mp: 3
  layers_pre_mp: 0
  msg_direction: single
  normalize_adj: False
  residual: False
  self_msg: concat
  skip_every: 1
  stage_type: stack
gpu_mem: False
gt:
  attn:
    O_e: True
    act: relu
    clamp: 5.0
    deg_scaler: True
    edge_enhance: True
    full_attn: True
    fwl: False
    norm_e: True
    sparse: False
    use: True
    use_bias: False
  attn_dropout: 0.2
  batch_norm: True
  bigbird:
    add_cross_attention: False
    attention_type: block_sparse
    block_size: 3
    chunk_size_feed_forward: 0
    hidden_act: relu
    is_decoder: False
    layer_norm_eps: 1e-06
    max_position_embeddings: 128
    num_random_blocks: 3
    use_bias: False
  bn_momentum: 0.1
  bn_no_runner: False
  dim_hidden: 64
  dropout: 0.0
  full_graph: True
  gamma: 1e-05
  layer_norm: False
  layer_type: GritTransformer
  layers: 10
  n_heads: 8
  pna_degrees: []
  residual: True
  update_e: True
mem:
  inplace: False
metric_agg: argmin
metric_best: mae
mlflow:
  name: zinc-GRIT-RRWP
  project: Exp
  use: False
model:
  edge_decoding: dot
  graph_pooling: add
  loss_fun: l1
  match_upper: True
  size_average: mean
  thresh: 0.5
  type: GritTransformer
name_tag: 
num_threads: 6
num_workers: 0
optim:
  base_lr: 0.001
  batch_accumulation: 1
  clip_grad_norm: True
  early_stop_by_lr: False
  early_stop_by_perf: False
  lr_decay: 0.1
  max_epoch: 2000
  min_lr: 1e-06
  min_lr_mode: threshold
  momentum: 0.9
  num_cycles: 0.5
  num_warmup_epochs: 50
  optimizer: adamW
  reduce_factor: 0.5
  schedule_patience: 10
  scheduler: cosine_with_warmup
  steps: [30, 60, 90]
  stop_patience: 100
  weight_decay: 1e-05
out_dir: results/zinc-GRIT-PPR
posenc_ElstaticSE:
  dim_pe: 16
  enable: False
  kernel:
    times: []
    times_func: range(10)
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_EquivStableLapPE:
  eigen:
    eigvec_norm: L2
    laplacian_norm: sym
    max_freqs: 10
  enable: False
  raw_norm_type: none
posenc_HKdiagSE:
  dim_pe: 16
  enable: False
  kernel:
    times: []
    times_func: 
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_LapPE:
  dim_pe: 16
  eigen:
    eigvec_norm: L2
    laplacian_norm: sym
    max_freqs: 10
  enable: False
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_PPR:
  dim_pe: 4
  eigen:
    eigvec_norm: L2
    laplacian_norm: none
    max_freqs: 4
  enable: True
  layers: 2
  model: DeepSet
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_RRWP:
  add_identity: True
  dim_pe: 16
  enable: False
  ksteps: 21
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
  spd: False
posenc_RWSE:
  dim_pe: 16
  enable: False
  kernel:
    times: []
    times_func: 
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_SVD:
  dim_pe: 16
  eigen:
    eigvec_norm: L2
    laplacian_norm: sym
    max_freqs: 10
  enable: False
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_SignNet:
  dim_pe: 16
  eigen:
    eigvec_norm: L2
    laplacian_norm: sym
    max_freqs: 10
  enable: False
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  phi_hidden_dim: 64
  phi_out_dim: 4
  post_layers: 0
  raw_norm_type: none
pretrained:
  dir: 
  freeze_main: False
  reset_prediction_head: True
print: both
round: 5
run_dir: results/zinc-GRIT-PPR/0
run_id: 0
run_multiple_splits: []
seed: 0
share:
  dim_in: 1
  dim_out: 1
  num_splits: 3
tensorboard_agg: True
tensorboard_each_run: True
train:
  auto_resume: False
  batch_size: 32
  ckpt_best: True
  ckpt_clean: True
  ckpt_period: 100
  enable_ckpt: True
  epoch_resume: -1
  eval_period: 1
  iter_per_epoch: 32
  mode: custom
  neighbor_sizes: [20, 15, 10, 5]
  node_per_graph: 32
  radius: extend
  sample_node: False
  sampler: full_batch
  skip_train_eval: False
  walk_length: 4
val:
  node_per_graph: 32
  radius: extend
  sample_node: False
  sampler: full_batch
view_emb: False
wandb:
  entity: gtransformers
  name: 
  project: ZINC
  use: False
work_dir: /usr/itetnas04/data-scratch-01/jiaxie/data/pe4gt
Num parameters: 470701
Start from epoch 0
train: {'epoch': 0, 'time_epoch': 27.53145, 'eta': 55035.36194, 'eta_hours': 15.2876, 'loss': 1.58415085, 'lr': 0.0, 'params': 470701, 'time_iter': 0.08796, 'mae': 1.58415, 'r2': -0.16879, 'spearmanr': -0.29452, 'mse': 4.7259, 'rmse': 2.17391}
...computing epoch stats took: 0.02s
val: {'epoch': 0, 'time_epoch': 0.8209, 'loss': 1.53976188, 'lr': 0, 'params': 470701, 'time_iter': 0.02565, 'mae': 1.53976, 'r2': -0.16153, 'spearmanr': -0.28621, 'mse': 4.57499, 'rmse': 2.13892}
...computing epoch stats took: 0.01s
test: {'epoch': 0, 'time_epoch': 0.82044, 'loss': 1.65636609, 'lr': 0, 'params': 470701, 'time_iter': 0.02564, 'mae': 1.65637, 'r2': -0.1686, 'spearmanr': -0.30291, 'mse': 4.75423, 'rmse': 2.18042}
...computing epoch stats took: 0.01s
> Epoch 0: took 29.2s (avg 29.2s) | Best so far: epoch 0	train_loss: 1.5842 train_mae: 1.5841	val_loss: 1.5398 val_mae: 1.5398	test_loss: 1.6564 test_mae: 1.6564
-----------------------------------------------------------
train: {'epoch': 1, 'time_epoch': 26.35244, 'eta': 53830.00721, 'eta_hours': 14.95278, 'loss': 1.03490651, 'lr': 2e-05, 'params': 470701, 'time_iter': 0.08419, 'mae': 1.03491, 'r2': 0.34156, 'spearmanr': 0.68846, 'mse': 2.66232, 'rmse': 1.63166}
...computing epoch stats took: 0.02s
val: {'epoch': 1, 'time_epoch': 0.75663, 'loss': 0.69482698, 'lr': 0, 'params': 470701, 'time_iter': 0.02364, 'mae': 0.69483, 'r2': 0.5693, 'spearmanr': 0.86002, 'mse': 1.69644, 'rmse': 1.30247}
...computing epoch stats took: 0.01s
test: {'epoch': 1, 'time_epoch': 0.75615, 'loss': 0.76892626, 'lr': 0, 'params': 470701, 'time_iter': 0.02363, 'mae': 0.76893, 'r2': 0.58849, 'spearmanr': 0.84275, 'mse': 1.67413, 'rmse': 1.29388}
...computing epoch stats took: 0.02s
> Epoch 1: took 27.9s (avg 28.6s) | Best so far: epoch 1	train_loss: 1.0349 train_mae: 1.0349	val_loss: 0.6948 val_mae: 0.6948	test_loss: 0.7689 test_mae: 0.7689
-----------------------------------------------------------
train: {'epoch': 2, 'time_epoch': 26.53366, 'eta': 53531.28029, 'eta_hours': 14.8698, 'loss': 0.66523669, 'lr': 4e-05, 'params': 470701, 'time_iter': 0.08477, 'mae': 0.66524, 'r2': 0.61683, 'spearmanr': 0.86713, 'mse': 1.5493, 'rmse': 1.24471}
...computing epoch stats took: 0.10s
val: {'epoch': 2, 'time_epoch': 0.7673, 'loss': 0.56609102, 'lr': 0, 'params': 470701, 'time_iter': 0.02398, 'mae': 0.56609, 'r2': 0.64708, 'spearmanr': 0.9, 'mse': 1.39007, 'rmse': 1.17901}
...computing epoch stats took: 0.08s
test: {'epoch': 2, 'time_epoch': 0.76566, 'loss': 0.61020714, 'lr': 0, 'params': 470701, 'time_iter': 0.02393, 'mae': 0.61021, 'r2': 0.65819, 'spearmanr': 0.88187, 'mse': 1.3906, 'rmse': 1.17924}
...computing epoch stats took: 0.06s
> Epoch 2: took 28.3s (avg 28.5s) | Best so far: epoch 2	train_loss: 0.6652 train_mae: 0.6652	val_loss: 0.5661 val_mae: 0.5661	test_loss: 0.6102 test_mae: 0.6102
-----------------------------------------------------------
